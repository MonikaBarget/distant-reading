<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Understanding and plotting probability distributions in NLP | DistantReading</title>
    <meta name="description" content="Files and documentation for teaching">
    <meta name="generator" content="VitePress v1.4.1">
    <link rel="preload stylesheet" href="/distant-reading/assets/style.9s32jwnt.css" as="style">
    
    <script type="module" src="/distant-reading/assets/app.D-dSdnSN.js"></script>
    <link rel="preload" href="/distant-reading/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/distant-reading/assets/chunks/theme.BD7D8kYy.js">
    <link rel="modulepreload" href="/distant-reading/assets/chunks/framework.Ccoi24fT.js">
    <link rel="modulepreload" href="/distant-reading/assets/pages_nlp_plottingdistribution.md.BRD_Dh4u.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-ab179fa1><a class="title" href="/distant-reading/" data-v-ab179fa1><!--[--><!--]--><!----><span data-v-ab179fa1>DistantReading</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/distant-reading/pages_datacollection.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Data Collection</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/distant-reading/pages_datacleaning.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Data Cleaning</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/distant-reading/pages_dataanalysis_samples.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Data Analysis Samples</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/distant-reading/pages_datasets_intro.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Datasets Intro</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>Data Scraping</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_applestore.html" data-v-35975db6><!--[--><span data-v-35975db6>Apple Store</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_googlenews.html" data-v-35975db6><!--[--><span data-v-35975db6>Google News</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_mastodon.html" data-v-35975db6><!--[--><span data-v-35975db6>Mastodon</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_Meta.html" data-v-35975db6><!--[--><span data-v-35975db6>Meta</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_reddit.html" data-v-35975db6><!--[--><span data-v-35975db6>Reddit</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_twitter.html" data-v-35975db6><!--[--><span data-v-35975db6>Twitter</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_datascraping_youtube.html" data-v-35975db6><!--[--><span data-v-35975db6>YouTube</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>NLP</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_nlp_segmentation.html" data-v-35975db6><!--[--><span data-v-35975db6>Segmentation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_nlp_topicmodels.html" data-v-35975db6><!--[--><span data-v-35975db6>Topic Models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link active" href="/distant-reading/pages_nlp_plottingdistribution.html" data-v-35975db6><!--[--><span data-v-35975db6>Plotting Distribution</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_nlp_multiplelanguages.html" data-v-35975db6><!--[--><span data-v-35975db6>Multiple Languages</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_nlp_spatialdata.html" data-v-35975db6><!--[--><span data-v-35975db6>Spatial Data</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>Skills</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills1_0_VPNclient.html" data-v-35975db6><!--[--><span data-v-35975db6>VPN Client</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills1_1_DSRI.html" data-v-35975db6><!--[--><span data-v-35975db6>DSRI</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills1_2a_scrapeAPPLEreviews.html" data-v-35975db6><!--[--><span data-v-35975db6>Scrape Apple Reviews</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills1_2b_scrapeYOUTUBEcomments.html" data-v-35975db6><!--[--><span data-v-35975db6>Scrape YouTube Comments</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills1_3_OpenRefine.html" data-v-35975db6><!--[--><span data-v-35975db6>OpenRefine</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills1_4_batchdownload.html" data-v-35975db6><!--[--><span data-v-35975db6>Batch Download</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills2_2_casestudy.html" data-v-35975db6><!--[--><span data-v-35975db6>Case Study</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills2_1_VoyantTools.html" data-v-35975db6><!--[--><span data-v-35975db6>Voyant Tools</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_skills3_presentations.html" data-v-35975db6><!--[--><span data-v-35975db6>Presentations</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>Task Sheets</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_bodyimage.html" data-v-35975db6><!--[--><span data-v-35975db6>Body Image</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_domesticviolence.html" data-v-35975db6><!--[--><span data-v-35975db6>Domestic Violence</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_elonmusk.html" data-v-35975db6><!--[--><span data-v-35975db6>Elon Musk</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_girlboss.html" data-v-35975db6><!--[--><span data-v-35975db6>Girlboss</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_epstein.html" data-v-35975db6><!--[--><span data-v-35975db6>Jeffrey Epstein</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_menstruation.html" data-v-35975db6><!--[--><span data-v-35975db6>Menstruation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_mileycyrus.html" data-v-35975db6><!--[--><span data-v-35975db6>Miley Cyrus</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_race.html" data-v-35975db6><!--[--><span data-v-35975db6>Race</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_seretsekhama.html" data-v-35975db6><!--[--><span data-v-35975db6>Seretse Khama</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_slavery.html" data-v-35975db6><!--[--><span data-v-35975db6>Slavery</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_sorayaesfandiary.html" data-v-35975db6><!--[--><span data-v-35975db6>Soraya Esfandiary</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_truecrime.html" data-v-35975db6><!--[--><span data-v-35975db6>True Crime</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_wastecolonialism.html" data-v-35975db6><!--[--><span data-v-35975db6>Waste Colonialism</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/distant-reading/pages_tasksheet_witchcraft.html" data-v-35975db6><!--[--><span data-v-35975db6>Witchcraft</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><span class="vpi-social-github" /></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-17a5e62e><button data-v-17a5e62e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h2 class="text" data-v-b7550ba0>External Links</h2><!----></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link vp-external-link-icon link" href="https://github.com/MonikaBarget/distant-reading" target="_blank" rel="noreferrer" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>GitHub Code</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link vp-external-link-icon link" href="https://www.youtube.com/@digitalhistory7990" target="_blank" rel="noreferrer" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>YouTube Channel</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _distant-reading_pages_nlp_plottingdistribution" data-v-39a288b8><div><h1 id="understanding-and-plotting-probability-distributions-in-nlp" tabindex="-1">Understanding and plotting probability distributions in NLP <a class="header-anchor" href="#understanding-and-plotting-probability-distributions-in-nlp" aria-label="Permalink to &quot;Understanding and plotting probability distributions in NLP&quot;">​</a></h1><h2 id="definition-of-probability-distribution" tabindex="-1">Definition of probability distribution <a class="header-anchor" href="#definition-of-probability-distribution" aria-label="Permalink to &quot;Definition of probability distribution&quot;">​</a></h2><p>According to the Geeks for Geeks article <a href="https://www.geeksforgeeks.org/statistics-in-natural-language-processing/" target="_blank" rel="noreferrer">Fundamentals of statistics in natural langauge processing</a>, a variety of statistical concepts and methods are used in NLP. One aspect are so-called <em>descriptive statistics</em>, which include frequency counts (e.g. represented in word clouds), measures of Central Tendency (mean, median, mode), and measures of dispersion (e.g. for analysing &quot;variability in word or sentence lengths&quot;). Another important statistical concept often used in NLP are so-called <em>probability distributions</em>.</p><p>Julia Hockenmaier, lecturer at the Sibel Center, University of Illinois, has outlined the most common probability models for NLP in <a href="https://courses.grainger.illinois.edu/cs447/fa2020/Slides/Lecture03.pdf" target="_blank" rel="noreferrer">a lecture for the course CS447: Natural Language Processing</a>. This lecture introduces students to how language models &quot;define probability distributions over the strings in a language&quot; (slide 5), explains n-gram models and outlines &quot;some very basic probability theory&quot;.</p><p>Slides 11 and 12 explain sampling with replacement (often covered in secondary school mathematics courses as well) and applies this process to a text as a &quot;bag of words&quot; (slide 13).</p><p>Page 16 defines a probability distribution over omega as frequently used in NLP. Page 17 explains discrete probability (fixed, often finite, number of outcomes), Bernoulli distribution, and categorical distribution. Page 18 moves on to the importance of joint probability (of two attributes, such as shape + colour), which leads to the so-called chain rule. (Slide 19) After defining the concept of an independent variable, slide 21 explains how a probability model (in NLP) is constructed from the model definition and the estimation of the model&#39;s parameters:</p><blockquote>Probability models (almost) always make independence assumptions. — Even though X and Y are not actually independent, our model may treat them as independent. — This can drastically reduce the number of parameters to estimate. — Models without independence assumptions have (way) too many parameters to estimate reliably from the data we have — But since independence assumptions are often incorrect, those models are often incorrect as well: they assign probability mass to events that cannot occur</blockquote><p>Slide 23: <blockquote>An n-gram language model assumes each word depends only on the last n−1 words.</blockquote></p><p>Slide 29 is important because it recounts a mathematical definition of language:</p><blockquote>CS447 Natural Language Processing (J. Hockenmaier) https://courses.grainger.illinois.edu/cs447/ From n-gram probabilities to language models Recall: a language L ⊆ V* is a (possibly infinite) set of strings over a (finite) vocabulary V. P(w(i) | w(i-1)) defines a distribution over the words in V: By multiplying this distribution N times, we get one distribution over all strings of the same length N (VN): Prob. of one N-word string: Prob. of all N-word strings But instead of N separate distributions… …we want one distribution over strings of any length ∀w ∈ V : [ ∑ w′∈V P(w(i) = w′ ∣ w(i−1) = w)] = 1 P(w1 . . . wN) = ∏ i=1...N P(w(i) = wi ∣ w(i−1) = wi−1) P(VN) = ∑ w,w′∈</blockquote><p>Elements that matter in language models are &quot;end-of-sentence&quot; (EOS) tokens. We end up with strings of varying lengths, but we want to be able to compare probabilities across all strings in a typical text, so it is important to calculate one distribution over the entire text. Vice versa, having one distribution makes it possible to &quot;generate strings of arbitrary length with one model.&quot; (Slide 32)</p><p>A large amount of text is needed as training data to &quot;learn&quot; or &quot;estimate&quot; the parameters typical of a language model and develop reliable probabilities. One basic technique is &quot;relative frequency estimation&quot;, also known as &quot;Maximum Likelihood Estimation&quot; (MLE), see slide 34. This can be fine-tuned by not only using EOS but also operating with &quot;beginning-of-sentence&quot; (BOS) symbols.</p><p>Language models cannot only be used to analyse language but also to (randomly) create sentences. (Slide 39) The examples given on the following slides do not necessarily make sense (yet) but show typical features of the text types chosen, e.g. frequently used vocabulary in a business journal or a Shakespeare work, combined with typical sentence structures. Differences between adjectives, verbs, adverbs and nouns are not recognized in this symbol model to a sufficient degree, but it is clear that the quadrigram output is more logical than the unigram output that just puts individual words behind each other. A quadigram output includes grammatically correct sentences like &quot;Will you not tell me who I am?&quot;</p><p>Slide 47 ff. describe &quot;smoothing methods&quot;, but those are not relevant for students who merely want to work with language models analytically.</p><p>Slide 50 differentiates between intrinsic and extrinsic evaluations of language models and addresses the challenges of defining evaluation metrics more generally.</p><p>Recommended lecture on <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=https://courses.grainger.illinois.edu/cs447/fa2020/Slides/Lecture03.pdf&amp;ved=2ahUKEwibh46n28yJAxXx9bsIHauuDNkQFnoECBMQAQ&amp;usg=AOvVaw2q5YGp2ei5kG-8cN3PGHY5" target="_blank" rel="noreferrer">Probability Models for NLP</a></p><p>To make texts consisting in many different words easier to visualise, <em>dimensionality reduction</em> is applied. This technique reduces high-dimensional data (data with a lot of information) to representative core features so that we can understand it more easily.</p><p>In NLP, you often find dimensionality reduction using the Principal Component Analysis (PCA) method, which finds the most important features or directions in the data. It keeps as much of the original information as possible. In NLP, PCA takes high-dimensional word representations (embeddings) and shows them in 2D or 3D plots so we can see patterns and relationships more clearly. t-SNE (t-Distributed Stochastic Neighbor Embedding) is another technique of dimension reduction, but it functions differently and creates semantic distributions. It focuses on keeping similar items close together and. It’s used for showing clusters of words or groups of documents in 2D or 3D, making it easier to spot patterns or groupings.</p><p>In <em>distributed representations</em>, also known as <em>embeddings</em>, the idea is that the &quot;meaning&quot; or &quot;semantic content&quot; of a data point is distributed across multiple dimensions. Expressing it more simply, distributed representations or embeddings are a way of representing words as numbers. These numbers, or vectors, are like coordinates in a space where each word is a point. Words that have similar meanings are placed near each other in this space. For example, the words &quot;cat&quot; and &quot;dog&quot; might be close together because they are both animals, while &quot;cat&quot; and &quot;car&quot; might be farther apart, since they&#39;re not related in meaning. There are special techniques, like Word2Vec, GloVe, and FastText, that learn how to place words in this space by looking at lots of text. The space can be a two-dimensional graph with an x- and a y-axes, with the different dots arranged between these axes. A plot like this is called a scatter plot.</p><h2 id="reading-scatter-plots" tabindex="-1">Reading scatter plots <a class="header-anchor" href="#reading-scatter-plots" aria-label="Permalink to &quot;Reading scatter plots&quot;">​</a></h2><p>In a scatter plot, the x-axis (horizontal) and y-axis (vertical) each represent a variable. Each dot drawn in a scatter plot corresponds to a unique observation in both dimensions. These dimensions can be absolute numbers, e.g. a person&#39;s age and income, or relative values, e.g. when we are considering word distrubitions in a text or a collection of texts.</p><p>When points group together in a scatter plot, it suggests a concentration of data in that range. If the points generally point upward (from bottom left to top right), it shows a positive correlation, meaning as one variable increases, the other tends increase, too.</p><p>📈 add sample graph for correlation between study time and grade</p><p>A downward slope shows a negative correlation.</p><p>If the points are scattered randomly with no clear slope or pattern, this indicates no relationship between the variables.</p><p>📈 add sample graph for number of pets and student grades</p><p>Some points may sit far away from the cluster, which could be outliers — unusual observations that differ significantly from the trend. These might signal unique cases or errors in data.</p><p>📋 find non-NLP example</p><p>Understanding scatter plots is not just about observing the dominant trend but about interpreting what the relationships of all points (or lack thereof) means. Ask questions like: “What could a strong positive correlation tell us about these two variables?”</p><p>In NLP, scatter plots are commonly used to show relationships or similarities between words, sentences, or entire documents. Each point represents a word, sentence, or document based on its embedding or similarity score. In contrast to a scatter plot in which values such as age, income, height, weight, or length are measured, an NLP scatter plot can have negative values on both the x and y axes because we deal with probability measures. Negative values represent dissimilarity where positive values express similarity.</p><p>📋 find non-NLP example based on data used for teaching</p><p>Depending on the context and the algorithms used, NLP scatter plots do not always represent the exact same values but can entail very different properties, like two different sentiment scores (e.g., positive and negative) or dimensions of similarity. So be carefuly to check what exactly is being shown before you begin your analysis!</p><p>In NLP scatter plots, clustering often indicates semantic similarity rather than direct co-occurrence in the text or corpus itself. The distance between points can then signal semantic similarity (closer points mean more similar meaning or sentiment). For example, &quot;doctor&quot; and &quot;nurse&quot; or &quot;master&quot; and &quot;slave&quot; might cluster together due to shared contexts in training data, but they don’t necessarily appear together in the text.</p><p>📋 add example using Voyant</p><p>This is why NLP scatter plots are similar to mind maps or conceptual maps rather than a structured representation of the text. Some algorithms may also result in point / words clusters in which words behave similarly in statistical terms while there is no content-based relationship between them.</p><p>📋 add example chart</p><p>Moreover, scatter plots in NLP sometimes reveal linear trends if there’s a direct relationship between two similarity measures, but more often display nonlinear clusters if embeddings capture complex, multidimensional meanings. Points far from clusters may represent unusual or ambiguous words, phrases, or sentences that do not fit into clear similarity groups. For example, highly context-dependent words or polysemous words (words with multiple meanings) might appear as outliers, indicating that they don’t neatly belong to a single cluster.</p><p>Special techniques, like Word2Vec, GloVe, and FastText, place words in the plot placed on word meanings and identify similar words, classify entire texts, or even translating languages. Some types of embeddings, like contextual embeddings (from models like BERT or GPT), do take the specific context into account, meaning each word has a unique embedding in each context. However, even in these cases, clustering will reflect shared meaning across contexts rather than specific occurrences within a particular text passage.</p><h2 id="understanding-the-scatter-plot-tool-in-voyant" tabindex="-1">Understanding the scatter plot tool in Voyant <a class="header-anchor" href="#understanding-the-scatter-plot-tool-in-voyant" aria-label="Permalink to &quot;Understanding the scatter plot tool in Voyant&quot;">​</a></h2><p>Unfortunately, the Voyant documentation for the scatter plot tool is quite abstract and short, not providing a lot of insight for beginners:</p><blockquote><p>Principal Component Analysis (PCA) is a technique which takes data in a multidimensional space and optimizes it, reducing the dimensions to a manageable subset. It is a way of transforming the data with respect to its own structure, so that associations between data points become more readily apparent. For example, consider a table of word frequencies for a corpus of ten documents. Each document can be thought of as a dimension, and each word frequency as a data point. Since we cannot visualize a ten dimensional space, we can apply PCA to reduce the number of dimensions to something feasible, like two or three. This is accomplished by transforming the data into a new space wherein the first few dimensions (or components) represent the largest amount of variability in the data. By discarding all but the first two or three dimensions, we will be left with a new data set which ideally contains most of the information in the original, but which is easy to visualize. In the resulting visualization, words that are grouped together are associated, i.e. they follow a similar usage in the corpus.</p></blockquote><blockquote><p>Correspondence Analysis is also conceptually similar to PCA, but handles the data in such a way that both the rows and columns are analyzed. This means that given a table of word frequencies, both the words themselves and the document segments will be plotted in the resulting visualization. Document Similarity is essentially the same as Correspondence Analysis, but terms aren&#39;t shown in the graph. The scatterplot is presented in the main display in the tool with a legend in the top left hand corner. Hovering over a word in the graph will display more information about the frequency of occurrence of that word.</p></blockquote><p>Above the main display is the primary toolbar and to the right of the display is sub-panel providing a list of words that appear in the corpus as well as their frequencies.</p><p>The tool allows you to change several parameters, but the documentation is not very detailed:</p><h3 id="options" tabindex="-1">Options <a class="header-anchor" href="#options" aria-label="Permalink to &quot;Options&quot;">​</a></h3><p>The toolbar mainly comprises options for tweaking and exploring the plotting of the graph.</p><pre><code>Analysis allows the user to switch between plotting Document Similarity, Principal Component Analysis and Correspondence Analysis
Clusters allows the user to control the number of groups to cluster the words into. These clusters are determined automatically by the criteria of the analysis and words in a cluster would indicate a measure of similarity between words. Clusters of terms will appear as a single colour.
Dimensions allows the user to switch between two or three dimensions.
Labels allows the user to cycle through the label settings for the graph.
</code></pre><h3 id="terms" tabindex="-1">Terms <a class="header-anchor" href="#terms" aria-label="Permalink to &quot;Terms&quot;">​</a></h3><p>The Terms panel shows you which terms are displayed in the Scatterplot and it also allows you to control which terms are shown.</p><p>The terms grid functions like other grids and you can sort terms alphabetically or by frequency. The Terms panel also provides the following functionality:</p><pre><code>Terms Count: determine how many terms to display at once in the graph (the terms present will influence the layout of the terms, so it&#39;s well worth experimenting with this option)
Nearby: you can select a term of interest from the grid and ask to zoom in on &quot;nearby&quot; terms (terms that cluster in proximity)
Remove: you can remove one term at a time by selecting it in the grid and hitting the Remove button
Add Term: you can search for and add new terms
</code></pre><p>🛠️ Under construction</p><h3 id="works-cited-and-recommendations-for-further-reading" tabindex="-1">Works cited and recommendations for further reading <a class="header-anchor" href="#works-cited-and-recommendations-for-further-reading" aria-label="Permalink to &quot;Works cited and recommendations for further reading&quot;">​</a></h3><p>Fundamentals of statistics in natural language processing(Nlp). (2024, July 15). GeeksforGeeks. <a href="https://www.geeksforgeeks.org/statistics-in-natural-language-processing" target="_blank" rel="noreferrer">https://www.geeksforgeeks.org/statistics-in-natural-language-processing</a></p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><!----></div><div class="pager" data-v-e257564d><a class="VPLink link vp-external-link-icon pager-link next" href="https://github.com/MonikaBarget/distant-reading" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>GitHub Code</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"lh-yEOY3\",\"index.md\":\"CWoAwYm5\",\"markdown-examples.md\":\"CATt-Usg\",\"pages_dataanalysis_samples.md\":\"Cj0ejkYY\",\"pages_datacleaning.md\":\"BB4XLPGt\",\"pages_datacollection.md\":\"CFbQKZLJ\",\"pages_datascraping_applestore.md\":\"C_7mwHHH\",\"pages_datascraping_googleapi.md\":\"aLJzD2kJ\",\"pages_datascraping_googlenews.md\":\"BqYKERQW\",\"pages_datascraping_mastodon.md\":\"BJsrUEtu\",\"pages_datascraping_meta.md\":\"Ccle9Oej\",\"pages_datascraping_reddit.md\":\"Bx5cwmwz\",\"pages_datascraping_twitter.md\":\"CL3nIHhx\",\"pages_datascraping_youtube.md\":\"DkJkDyl7\",\"pages_datasets_intro.md\":\"Xa5-___l\",\"pages_nlp_introduction.md\":\"CYhaUC_W\",\"pages_nlp_multiplelanguages.md\":\"B8tLqMnq\",\"pages_nlp_plottingdistribution.md\":\"BRD_Dh4u\",\"pages_nlp_segmentation.md\":\"CDY22Kyx\",\"pages_nlp_spatialdata.md\":\"BCT5m33q\",\"pages_nlp_topicmodels.md\":\"BYyMJTeU\",\"pages_skills1_0_vpnclient.md\":\"CUEeE0Fs\",\"pages_skills1_1_dsri.md\":\"Mp7yg5Ol\",\"pages_skills1_2a_scrapeapplereviews.md\":\"BMrcFNWX\",\"pages_skills1_2b_scrapeyoutubecomments.md\":\"FvinYHHR\",\"pages_skills1_3_openrefine.md\":\"BdnPRtCl\",\"pages_skills1_4_batchdownload.md\":\"ClwwFpsa\",\"pages_skills2_1_voyanttools.md\":\"BMwy62Ur\",\"pages_skills2_2_casestudy.md\":\"Cbc9_XYi\",\"pages_skills3_presentations.md\":\"DiEJadje\",\"pages_tasksheet_bodyimage.md\":\"DMsBN7rR\",\"pages_tasksheet_domesticviolence.md\":\"6EfgRd3w\",\"pages_tasksheet_elonmusk.md\":\"Ojv-FkUQ\",\"pages_tasksheet_epstein.md\":\"BVhVt9bS\",\"pages_tasksheet_girlboss.md\":\"B6PeUZP3\",\"pages_tasksheet_menstruation.md\":\"Dpix_Ksb\",\"pages_tasksheet_mileycyrus.md\":\"DSSDvTkm\",\"pages_tasksheet_race.md\":\"D8n4y0rB\",\"pages_tasksheet_seretsekhama.md\":\"Bujd4t55\",\"pages_tasksheet_slavery.md\":\"CGZMA747\",\"pages_tasksheet_sorayaesfandiary.md\":\"B_2hupuq\",\"pages_tasksheet_truecrime.md\":\"CURIh1_4\",\"pages_tasksheet_wastecolonialism.md\":\"DWRNrmjR\",\"pages_tasksheet_witchcraft.md\":\"BhxoUk_L\",\"pages_welcome.md\":\"B6GL1-S-\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"DistantReading\",\"description\":\"Files and documentation for teaching\",\"base\":\"/distant-reading/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Data Collection\",\"link\":\"/pages_datacollection.md\"},{\"text\":\"Data Cleaning\",\"link\":\"/pages_datacleaning.md\"},{\"text\":\"Data Analysis Samples\",\"link\":\"/pages_dataanalysis_samples.md\"},{\"text\":\"Datasets Intro\",\"link\":\"/pages_datasets_intro.md\"},{\"text\":\"Data Scraping\",\"items\":[{\"text\":\"Apple Store\",\"link\":\"/pages_datascraping_applestore.md\"},{\"text\":\"Google News\",\"link\":\"/pages_datascraping_googlenews.md\"},{\"text\":\"Mastodon\",\"link\":\"/pages_datascraping_mastodon.md\"},{\"text\":\"Meta\",\"link\":\"/pages_datascraping_Meta.md\"},{\"text\":\"Reddit\",\"link\":\"/pages_datascraping_reddit.md\"},{\"text\":\"Twitter\",\"link\":\"/pages_datascraping_twitter.md\"},{\"text\":\"YouTube\",\"link\":\"/pages_datascraping_youtube.md\"}]},{\"text\":\"NLP\",\"items\":[{\"text\":\"Segmentation\",\"link\":\"/pages_nlp_segmentation.md\"},{\"text\":\"Topic Models\",\"link\":\"/pages_nlp_topicmodels.md\"},{\"text\":\"Plotting Distribution\",\"link\":\"/pages_nlp_plottingdistribution.md\"},{\"text\":\"Multiple Languages\",\"link\":\"/pages_nlp_multiplelanguages.md\"},{\"text\":\"Spatial Data\",\"link\":\"/pages_nlp_spatialdata.md\"}]},{\"text\":\"Skills\",\"items\":[{\"text\":\"VPN Client\",\"link\":\"/pages_skills1_0_VPNclient.md\"},{\"text\":\"DSRI\",\"link\":\"/pages_skills1_1_DSRI.md\"},{\"text\":\"Scrape Apple Reviews\",\"link\":\"/pages_skills1_2a_scrapeAPPLEreviews.md\"},{\"text\":\"Scrape YouTube Comments\",\"link\":\"/pages_skills1_2b_scrapeYOUTUBEcomments.md\"},{\"text\":\"OpenRefine\",\"link\":\"/pages_skills1_3_OpenRefine.md\"},{\"text\":\"Batch Download\",\"link\":\"/pages_skills1_4_batchdownload.md\"},{\"text\":\"Case Study\",\"link\":\"/pages_skills2_2_casestudy.md\"},{\"text\":\"Voyant Tools\",\"link\":\"/pages_skills2_1_VoyantTools.md\"},{\"text\":\"Presentations\",\"link\":\"/pages_skills3_presentations.md\"}]},{\"text\":\"Task Sheets\",\"items\":[{\"text\":\"Body Image\",\"link\":\"/pages_tasksheet_bodyimage.md\"},{\"text\":\"Domestic Violence\",\"link\":\"/pages_tasksheet_domesticviolence.md\"},{\"text\":\"Elon Musk\",\"link\":\"/pages_tasksheet_elonmusk.md\"},{\"text\":\"Girlboss\",\"link\":\"/pages_tasksheet_girlboss.md\"},{\"text\":\"Jeffrey Epstein\",\"link\":\"/pages_tasksheet_epstein.md\"},{\"text\":\"Menstruation\",\"link\":\"/pages_tasksheet_menstruation.md\"},{\"text\":\"Miley Cyrus\",\"link\":\"/pages_tasksheet_mileycyrus.md\"},{\"text\":\"Race\",\"link\":\"/pages_tasksheet_race.md\"},{\"text\":\"Seretse Khama\",\"link\":\"/pages_tasksheet_seretsekhama.md\"},{\"text\":\"Slavery\",\"link\":\"/pages_tasksheet_slavery.md\"},{\"text\":\"Soraya Esfandiary\",\"link\":\"/pages_tasksheet_sorayaesfandiary.md\"},{\"text\":\"True Crime\",\"link\":\"/pages_tasksheet_truecrime.md\"},{\"text\":\"Waste Colonialism\",\"link\":\"/pages_tasksheet_wastecolonialism.md\"},{\"text\":\"Witchcraft\",\"link\":\"/pages_tasksheet_witchcraft.md\"}]}],\"sidebar\":[{\"text\":\"External Links\",\"items\":[{\"text\":\"GitHub Code\",\"link\":\"https://github.com/MonikaBarget/distant-reading\"},{\"text\":\"YouTube Channel\",\"link\":\"https://www.youtube.com/@digitalhistory7990\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/vuejs/vitepress\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>